{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prueba del mejor algoritmo de aprendizaje automático para la predicción."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este notebook o libro, tarda unos 40 minutos en ejecutarse, pero ya lo hemos ejecutado y guardado los datos por usted. Sin embargo, léalo para que entienda cómo llegamos a las conclusiones que usaremos en el futuro. k takes about 40 minutes to run, but we've already run it and saved the data for you. Please read through it, though, so that you understand how we came to the conclusions we'll use moving forward.\n",
    "\n",
    "## Seis algoritmos\n",
    "\n",
    "Vamos a comparar seis algoritmos diferentes para determinar el mejor para producir un modelo preciso para nuestras predicciones.\n",
    "\n",
    "### Regresión logística\n",
    "\n",
    "La Regresión Logística (LR) es una técnica tomada del campo de la estadística. Es el método de consulta para problemas de clasificación binaria (problemas con dos valores de clase).\n",
    "\n",
    "![](./docs/logisticfunction.png)\n",
    "\n",
    "La regresión logística se llama así por la función utilizada en el interior del método: La función logística. La función logística es un método probablístico utilizado para determinar si el conductor será o no el ganador. La regresión logística predice probabilidades.\n",
    "\n",
    "### Decision Tree (Árbol de decisión)\n",
    "\n",
    "Un árbol tiene muchas analogías en la vida real, y resulta que ha influido en una amplia área del aprendizaje automático, que abarca tanto la clasificación como la regresión. En el análisis de decisiones, un árbol de decisiones se puede utilizar para representar visual y explícitamente las decisiones y la toma de decisiones.\n",
    "![](./docs/decisiontree.png)\n",
    "\n",
    "Esta metodología se conoce más comúnmente como un \"árbol de decisión\" a partir de datos, y el árbol de la gráfica anterior se llama árbol de clasificación porque el objetivo es clasificar a un conductor como ganador o no.\n",
    "### Random Forest\n",
    "\n",
    "Random forest es un algoritmo de aprendizaje supervisado. El \"bosque\" que construye es un **conjunto de árboles de decisión**, generalmente entrenados con el método \" bagging \", una combinación de modelos de aprendizaje que aumenta la precisión del resultado.\n",
    "Un bosque aleatorio erradica las limitaciones de un algoritmo de árbol de decisión. Reduce el sobreajuste de los conjuntos de datos y aumenta la precisión. Genera predicciones sin requerir muchas configuraciones.\n",
    "\n",
    "![](./docs/randomforest.png)\n",
    "\n",
    "Esta es la diferencia entre los métodos árbol de decisión y bosque aleatorio:\n",
    "\n",
    "![](./docs/treefortheforest.jpg)\n",
    "\n",
    "### Support Vector Machine Algorithm (SVC)\n",
    "\n",
    "Support Vector Machines (SVMs) son un conjunto de métodos de aprendizaje supervisado utilizados para la clasificación, regresión y detección de valores atípicos.\n",
    "\n",
    "Las ventajas de las máquinas vectoriales de soporte son:\n",
    "\n",
    "- Eficaz en espacios de alta dimensión\n",
    "- Sigue siendo eficaz en los casos en que el número de dimensiones es mayor que el número de muestras.\n",
    "- Utiliza un subconjunto de puntos de entrenamiento en la función de decisión (llamados vectores de apoyo), por lo que también es eficiente en memoria.\n",
    "- Versátil: se pueden especificar diferentes funciones del kernel para la función de decisión. Se proporcionan núcleos comunes, pero también es posible especificar núcleos personalizados.\n",
    "\n",
    "El objetivo de un SVC  (Support Vector Classifier) es ajustarse a los datos que proporciona, devolviendo un hiperplano de \"mejor ajuste\" que divide o categoriza sus datos.\n",
    "\n",
    "### Gaussian Naive Bayes Algorithm\n",
    "\n",
    "Naive Bayes es un algoritmo de clasificación para problemas de clasificación binarios (dos clases) y multi-clase. La técnica es más fácil de entender cuando se describe utilizando valores de entrada binarios o categóricos. La representación utilizada para el naive Bayes son las probabilidades.\n",
    "\n",
    "Una lista de probabilidades se almacena en un archivo para un modelo de Naive Bayes. Esto incluye:\n",
    "\n",
    "- **Class Probabilities:** Las probabilidades de cada clase en el conjunto de datos de entrenamiento.\n",
    "- **Conditional Probabilities:** Las probabilidades condicionales de cada valor de entrada dado cada valor de clase.\n",
    "\n",
    "Naive Bayes se puede extender a atributos de valor real, más comúnmente asumiendo una distribución gaussiana. Esta extensión de Naive Bayes se llama Gaussian Naive Bayes. Se pueden usar otras funciones para estimar la distribución de los datos, pero la distribución gaussiana (o normal) es la más fácil de trabajar porque solo necesita estimar la media y la desviación estándar de sus datos de entrenamiento.\n",
    "\n",
    "### k Nearest Neighbor Algorithm (kNN)\n",
    "\n",
    "El k-Nearest Neighbors (KNN) es un algoritmo de aprendizaje automático simple y supervisado que se puede usar para resolver problemas de clasificación y regresión.\n",
    "\n",
    "KNN funciona encontrando las distancias entre una consulta y todos los ejemplos en los datos, seleccionando los ejemplos de números especificados (k) más cercanos a la consulta, luego votando por la etiqueta más frecuente (en el caso de la clasificación) o promediando las etiquetas (en el caso de la regresión).\n",
    "\n",
    "El algoritmo kNN asume la similitud entre el nuevo caso/datos y los casos disponibles, y coloca el nuevo caso en la categoría que es más similar a las categorías disponibles.\n",
    "\n",
    "![](./docs/knn.png)\n",
    "\n",
    "## Análisis de los datos\n",
    "\n",
    "### Importancia de las características o variables.\n",
    "\n",
    "Otra gran cualidad del algoritmo de los bosque aleatorios (random forest) es que es fácil medir la importancia relativa de cada característica para la predicción.\n",
    "\n",
    "La biblioteca Python Scikit-learn proporciona una gran herramienta para esto que mide la importancia de una característica al observar cuánto reducen la impureza los nodos de árbol que usan esa característica en todos los árboles del bosque. Calcula esta puntuación automáticamente para cada característica después del entrenamiento y escala los resultados para que la suma de toda la importancia sea igual a una.\n",
    "\n",
    "### Visualización de datos al crear un modelo\n",
    "\n",
    "¿Cómo visualizas la influencia de los datos? ¿Cómo se enmarca el problema?\n",
    "\n",
    "Una herramienta importante en el kit de herramientas del científico de datos es el poder de visualizar datos utilizando varias bibliotecas excelentes como Seaborn o MatPlotLib. Representar sus datos visualmente podría permitirle descubrir correlaciones ocultas que puede aprovechar. Sus visualizaciones también pueden ayudarlo a descubrir sesgos o datos desequilibrado.\n",
    "\n",
    "![](./docs/visualization.png)\n",
    "\n",
    "### División del conjunto de datos\n",
    "\n",
    "\n",
    "Antes del entrenamiento, se debe dividir su conjunto de datos en dos o más partes de tamaño desigual que aún representen bien los datos.\n",
    "\n",
    "1. Training. Esta parte del conjunto de datos se ajusta a su modelo para entrenarlo. Este conjunto constituye la mayoría del conjunto de datos original.\n",
    "2. Testing. Un conjunto de datos de prueba es un grupo independiente de datos, a menudo un subconjunto de los datos originales, que se utiliza para confirmar el rendimiento del modelo que ha creado.\n",
    "3. Validating. Un conjunto de validación es un grupo independi\n",
    "ente más pequeño de ejemplos que se utiliza para ajustar los hiperparámetros o la arquitectura del modelo para mejorar el modelo. Dependiendo del tamaño de sus datos y de la pregunta que esté haciendo, es posible que no necesite crear este tercer conjunto.\u000b",
    "\u000b",
    "\n",
    "\n",
    "## Creación del modelo\n",
    "\n",
    "Usando sus datos de entrenamiento, su objetivo es construir un modelo, o una representación estadística de sus datos, utilizando varios algoritmos para entrenarlos. Entrenar un modelo lo expone a los datos y le permite hacer suposiciones sobre los patrones percibidos que descubre, valida y acepta o rechaza.\n",
    "\n",
    "### Decidir sobre un método de entrenamiento\n",
    "\n",
    "Dependiendo de su pregunta y la naturaleza de sus datos, elegirá un método para entrenarlo. Al revisar la documentación de Scikit-learn, puede explorar muchas formas de entrenar a un modelo. Dependiendo de los resultados que obtenga, es posible que tenga que probar varios métodos diferentes para crear el mejor modelo. Es probable que pase por un proceso mediante el cual los científicos de datos evalúan el rendimiento de un modelo alimentándolo con datos no vistos por el modelo, verificando la precisión, el sesgo y otros problemas que degradan la calidad, y seleccionando el método de entrenamiento más adecuado para la tarea en cuestión.\n",
    "\n",
    "### Entrenar un modelo\n",
    "\n",
    "Armado con sus datos de entrenamiento, está listo para \"aprender\" y para crear un modelo. En muchas bibliotecas de ML encontrará el código 'model.fit': es en este momento que envía sus datos como una matriz de valores (generalmente 'X') y una variable de característica (generalmente 'y').\n",
    "\n",
    "### Evaluate the Model\n",
    "\n",
    "Una vez que se complete el proceso de entrenamiento, podrá evaluar la calidad del modelo utilizando datos de prueba para medir su rendimiento. Estos datos son un subconjunto de los datos originales que el modelo no ha analizado previamente. Puede imprimir una tabla de métricas sobre la calidad de su modelo.\n",
    "\n",
    "####  Ajuste del modelo\n",
    "\n",
    "En el contexto del aprendizaje automático, el ajuste del modelo se refiere a la precisión de la función subyacente del modelo, ya que intenta analizar datos con los que no está familiarizado.\n",
    "\n",
    "#### Subajuste y sobreajuste\n",
    "\n",
    "El subajuste y el sobreajuste son problemas comunes que degradan la calidad del modelo, ya que el modelo no se ajusta lo suficientemente bien o se ajusta demasiado bien. Esto hace que el modelo haga predicciones demasiado alineadas o demasiado poco alineadas con sus datos de entrenamiento. Un modelo de sobreajuste predice demasiado bien los datos de entrenamiento porque ha aprendido demasiado bien los detalles y el ruido de los datos. Un modelo de subacondicionamiento no es preciso, ya que no puede analizar con precisión sus datos de entrenamiento ni los datos que aún no ha \"visto\".\n",
    "\n",
    "![](./docs/overfit.png)\n",
    "\n",
    "Probemos algunos algoritmos para elegir nuestra ruta para modelar nuestras predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from sklearn.metrics import confusion_matrix, precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder,OneHotEncoder\n",
    "from sklearn.model_selection import cross_val_score,StratifiedKFold,RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix,precision_score,f1_score,recall_score\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "np.set_printoptions(precision=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data_f1/data_filtered.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dnf_by_driver = data.groupby('driver').sum()['driver_dnf']\n",
    "driver_race_entered = data.groupby('driver').count()['driver_dnf']\n",
    "driver_dnf_ratio = (dnf_by_driver/driver_race_entered)\n",
    "driver_confidence = 1-driver_dnf_ratio\n",
    "driver_confidence_dict = dict(zip(driver_confidence.index,driver_confidence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "driver_confidence_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dnf_by_constructor = data.groupby('constructor').sum()['constructor_dnf']\n",
    "constructor_race_entered = data.groupby('constructor').count()['constructor_dnf']\n",
    "constructor_dnf_ratio = (dnf_by_constructor/constructor_race_entered)\n",
    "constructor_reliability = 1-constructor_dnf_ratio\n",
    "constructor_reliability_dict = dict(zip(constructor_reliability.index,constructor_reliability))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "constructor_reliability_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data['driver_confidence'] = data['driver'].apply(lambda x:driver_confidence_dict[x])\n",
    "data['constructor_reliability'] = data['constructor'].apply(lambda x:constructor_reliability_dict[x])\n",
    "#removing retired drivers and constructors\n",
    "active_constructors = ['Alpine F1', 'Williams', 'McLaren', 'Ferrari', 'Mercedes',\n",
    "                       'AlphaTauri', 'Aston Martin', 'Alfa Romeo', 'Red Bull',\n",
    "                       'Haas F1 Team']\n",
    "active_drivers = ['Daniel Ricciardo', 'Mick Schumacher', 'Carlos Sainz',\n",
    "                  'Valtteri Bottas', 'Lance Stroll', 'George Russell',\n",
    "                  'Lando Norris', 'Sebastian Vettel', 'Kimi Räikkönen',\n",
    "                  'Charles Leclerc', 'Lewis Hamilton', 'Yuki Tsunoda',\n",
    "                  'Max Verstappen', 'Pierre Gasly', 'Fernando Alonso',\n",
    "                  'Sergio Pérez', 'Esteban Ocon', 'Antonio Giovinazzi',\n",
    "                  'Nikita Mazepin','Nicholas Latifi']\n",
    "data['active_driver'] = data['driver'].apply(lambda x: int(x in active_drivers))\n",
    "data['active_constructor'] = data['constructor'].apply(lambda x: int(x in active_constructors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directory to store Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists('./models'):\n",
    "    os.mkdir('./models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def position_index(x):\n",
    "    if x<4:\n",
    "        return 1\n",
    "    if x>10:\n",
    "        return 3\n",
    "    else :\n",
    "        return 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model considering only Drivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x_d= data[['GP_name','quali_pos','driver','age_at_gp_in_days','position','driver_confidence','active_driver']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x_d = x_d[x_d['active_driver']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sc  = StandardScaler()\n",
    "le = LabelEncoder()\n",
    "x_d['GP_name'] = le.fit_transform(x_d['GP_name'])\n",
    "x_d['driver'] = le.fit_transform(x_d['driver'])\n",
    "x_d['GP_name'] = le.fit_transform(x_d['GP_name'])\n",
    "x_d['age_at_gp_in_days'] = sc.fit_transform(x_d[['age_at_gp_in_days']])\n",
    "X_d = x_d.drop(['position','active_driver'],1)\n",
    "y_d = x_d['position'].apply(lambda x: position_index(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#cross validation for diffrent models\n",
    "models = [LogisticRegression(),DecisionTreeClassifier(),RandomForestClassifier(),SVC(),GaussianNB(),KNeighborsClassifier()]\n",
    "names = ['LogisticRegression','DecisionTreeClassifier','RandomForestClassifier','SVC','GaussianNB','KNeighborsClassifier']\n",
    "model_dict = dict(zip(models,names))\n",
    "mean_results_dri = []\n",
    "results_dri = []\n",
    "name = []\n",
    "for model in models:\n",
    "    cv = StratifiedKFold(n_splits=10,random_state=1,shuffle=True)\n",
    "    result = cross_val_score(model,X_d,y_d,cv=cv,scoring='accuracy')\n",
    "    mean_results_dri.append(result.mean())\n",
    "    results_dri.append(result)\n",
    "    name.append(model_dict[model])\n",
    "    print(f'{model_dict[model]} : {result.mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "plt.boxplot(x=results_dri,labels=name)\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Model performance comparision (drivers only)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model considering only Constructors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x_c = data[['GP_name','quali_pos','constructor','position','constructor_reliability','active_constructor']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x_c = x_c[x_c['active_constructor']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sc  = StandardScaler()\n",
    "le = LabelEncoder()\n",
    "x_c['GP_name'] = le.fit_transform(x_c['GP_name'])\n",
    "x_c['constructor'] = le.fit_transform(x_c['constructor'])\n",
    "X_c = x_c.drop(['position','active_constructor'],1)\n",
    "y_c = x_c['position'].apply(lambda x: position_index(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#cross validation for diffrent models\n",
    "models = [LogisticRegression(),DecisionTreeClassifier(),RandomForestClassifier(),SVC(),GaussianNB(),KNeighborsClassifier()]\n",
    "names = ['LogisticRegression','DecisionTreeClassifier','RandomForestClassifier','SVC','GaussianNB','KNeighborsClassifier']\n",
    "model_dict = dict(zip(models,names))\n",
    "mean_results_const = []\n",
    "results_const = []\n",
    "name = []\n",
    "for model in models:\n",
    "    cv = StratifiedKFold(n_splits=10,random_state=1,shuffle=True)\n",
    "    result = cross_val_score(model,X_c,y_c,cv=cv,scoring='accuracy')\n",
    "    mean_results_const.append(result.mean())\n",
    "    results_const.append(result)\n",
    "    name.append(model_dict[model])\n",
    "    print(f'{model_dict[model]} : {result.mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "plt.boxplot(x=results_const,labels=name)\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Model performance comparision (Teams only)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model considering both Drivers and Constructors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cleaned_data = data[['GP_name','quali_pos','constructor','driver','position','driver_confidence','constructor_reliability','active_driver','active_constructor']]\n",
    "cleaned_data = cleaned_data[(cleaned_data['active_driver']==1)&(cleaned_data['active_constructor']==1)]\n",
    "cleaned_data.to_csv('./data_f1/cleaned_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build your X dataset with next columns:\n",
    "- GP_name\n",
    "- quali_pos to predict the classification cluster (1,2,3) \n",
    "- constructor\n",
    "- driver\n",
    "- position\n",
    "- driver confidence\n",
    "- constructor_reliability\n",
    "- active_driver\n",
    "- active_constructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter the dataset for this Model \"Driver + Constructor\" all active drivers and constructors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Standard Scaler and Label Encoder for the different features in order to have a similar scale for all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the X (Features dataset) and y for predicted value. \n",
    "In our case, we want to calculate the cluster of final position for ech driver using the \"position_index\" function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Implement X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applied the same list of ML Algorithms for cross validation of different models\n",
    "\n",
    "And Store the accuracy Mean Value in order to compare with previous ML Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mean_results = []\n",
    "results = []\n",
    "name = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# cross validation for different models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the same boxplot plotter used in the previous Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Implement boxplot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing The 3 ML Models\n",
    "\n",
    "Let's see mean score of our three assumptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lr = [mean_results[0],mean_results_dri[0],mean_results_const[0]]\n",
    "dtc = [mean_results[1],mean_results_dri[1],mean_results_const[1]]\n",
    "rfc = [mean_results[2],mean_results_dri[2],mean_results_const[2]]\n",
    "svc = [mean_results[3],mean_results_dri[3],mean_results_const[3]]\n",
    "gnb = [mean_results[4],mean_results_dri[4],mean_results_const[4]]\n",
    "knn = [mean_results[5],mean_results_dri[5],mean_results_const[5]]\n",
    "font1 = {\n",
    "    'family':'serif',\n",
    "    'color':'black',\n",
    "    'weight':'normal',\n",
    "    'size':18\n",
    "}\n",
    "font2 = {\n",
    "    'family':'serif',\n",
    "    'color':'black',\n",
    "    'weight':'bold',\n",
    "    'size':12\n",
    "}\n",
    "x_ax = np.arange(3)\n",
    "plt.figure(figsize=(30,15))\n",
    "bar1 = plt.bar(x_ax,lr,width=0.1,align='center', label=\"Logistic Regression\")\n",
    "bar2 = plt.bar(x_ax+0.1,dtc,width=0.1,align='center', label=\"DecisionTree\")\n",
    "bar3 = plt.bar(x_ax+0.2,rfc,width=0.1,align='center',  label=\"RandomForest\")\n",
    "bar4 = plt.bar(x_ax+0.3,svc,width=0.1,align='center', label=\"SVC\")\n",
    "bar5 = plt.bar(x_ax+0.4,gnb,width=0.1,align='center', label=\"GaussianNB\")\n",
    "bar6 = plt.bar(x_ax+0.5,knn,width=0.1,align='center', label=\"KNN\")\n",
    "plt.text(0.05,1,'CV score for combined data',fontdict=font1)\n",
    "plt.text(1.04,1,'CV score only driver data',fontdict=font1)\n",
    "plt.text(2,1,'CV score only team data',fontdict=font1)\n",
    "for bar in bar1.patches:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x()+0.01,yval+0.01,f'{round(yval*100,2)}%',fontdict=font2)\n",
    "for bar in bar2.patches:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x()+0.01,yval+0.01,f'{round(yval*100,2)}%',fontdict=font2)\n",
    "for bar in bar3.patches:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x()+0.01,yval+0.01,f'{round(yval*100,2)}%',fontdict=font2)\n",
    "for bar in bar4.patches:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x()+0.01,yval+0.01,f'{round(yval*100,2)}%',fontdict=font2)\n",
    "for bar in bar5.patches:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x()+0.01,yval+0.01,f'{round(yval*100,2)}%',fontdict=font2)\n",
    "for bar in bar6.patches:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x()+0.01,yval+0.01,f'{round(yval*100,2)}%',fontdict=font2)\n",
    "plt.legend(loc='center', bbox_to_anchor=(0.5, -0.10), shadow=False, ncol=6)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "str(datetime.timedelta(seconds=(end - start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(str(end - start)+\" seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
